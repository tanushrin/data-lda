{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Dirichlet Allocation (LDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéØ The goal of this challenge is to find topics within a corpus of emails with the **LDA** algorithm (Unsupervised Learning in NLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úâÔ∏è Here is a collection of 1K+ ***unlabelled emails***. Let's try to ***extract topics*** from them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: gld@cunixb.cc.columbia.edu (Gary L Dare)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: atterlep@vela.acs.oakland.edu (Cardinal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: miner@kuhub.cc.ukans.edu\\nSubject: Re: A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: atterlep@vela.acs.oakland.edu (Cardinal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: vzhivov@superior.carleton.ca (Vladimir Z...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  From: gld@cunixb.cc.columbia.edu (Gary L Dare)...\n",
       "1  From: atterlep@vela.acs.oakland.edu (Cardinal ...\n",
       "2  From: miner@kuhub.cc.ukans.edu\\nSubject: Re: A...\n",
       "3  From: atterlep@vela.acs.oakland.edu (Cardinal ...\n",
       "4  From: vzhivov@superior.carleton.ca (Vladimir Z..."
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = 'https://wagon-public-datasets.s3.amazonaws.com/05-Machine-Learning/10-Natural-Language-Processing/lda_data'\n",
    "\n",
    "data = pd.read_csv(url, sep=\",\", header=None)\n",
    "data.columns = ['text']\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1199, 1)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (Cleaning**) ‚ùì You're used to it by now... Clean up! Store the cleaned text in a new column \"clean_text\" of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: gld@cunixb.cc.columbia.edu (Gary L Dare)...</td>\n",
       "      <td>gary l dare subject stan fischler summary devi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: atterlep@vela.acs.oakland.edu (Cardinal ...</td>\n",
       "      <td>cardinal ximenez subject arrogance christian o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: miner@kuhub.cc.ukans.edu\\nSubject: Re: A...</td>\n",
       "      <td>subject ancient book organization university k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: atterlep@vela.acs.oakland.edu (Cardinal ...</td>\n",
       "      <td>cardinal ximenez subject atheist hell organiza...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: vzhivov@superior.carleton.ca (Vladimir Z...</td>\n",
       "      <td>vladimir zhivov subject flame truly brutal los...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  From: gld@cunixb.cc.columbia.edu (Gary L Dare)...   \n",
       "1  From: atterlep@vela.acs.oakland.edu (Cardinal ...   \n",
       "2  From: miner@kuhub.cc.ukans.edu\\nSubject: Re: A...   \n",
       "3  From: atterlep@vela.acs.oakland.edu (Cardinal ...   \n",
       "4  From: vzhivov@superior.carleton.ca (Vladimir Z...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  gary l dare subject stan fischler summary devi...  \n",
       "1  cardinal ximenez subject arrogance christian o...  \n",
       "2  subject ancient book organization university k...  \n",
       "3  cardinal ximenez subject atheist hell organiza...  \n",
       "4  vladimir zhivov subject flame truly brutal los...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "import string\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def preprocessing(sentence):\n",
    "    #pass  # YOUR CODE HERE\n",
    "    #Remove whitespace\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    #Remove lowercase\n",
    "    sentence = sentence.lower()\n",
    "\n",
    "    #Remove numbers\n",
    "    sentence = ''.join([i for i in sentence if not i.isdigit()])\n",
    "\n",
    "    #Remove punctuation\n",
    "    sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    #Tokenize\n",
    "    sentence = word_tokenize(sentence)\n",
    "\n",
    "    #Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    sentence = [word for word in sentence if word not in stop_words]\n",
    "\n",
    "    #Lemmatize\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    sentence = [lemmatizer.lemmatize(word) for word in sentence]\n",
    "    sentence = ' '.join(sentence)\n",
    "\n",
    "\n",
    "    return sentence\n",
    "\n",
    "data['clean_text'] = data['text'].apply(preprocessing)\n",
    "# Remove the first word of each sentence\n",
    "data['clean_text'] = data['clean_text'].str.split(' ').str[1:].str.join(' ')\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Latent Dirichlet Allocation model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (Training)** ‚ùì Train a LDA model to extract potential topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    aa  \\\n",
      "0  0.0   \n",
      "1  0.0   \n",
      "2  0.0   \n",
      "\n",
      "   aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaauuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuugggggggggggggggg  \\\n",
      "0                                                0.0                                 \n",
      "1                                                0.0                                 \n",
      "2                                                0.0                                 \n",
      "\n",
      "   aacc  aadams  aafreenetcarletonca  aargh  aaron  aaronbinahccbrandeisedu  \\\n",
      "0   0.0     0.0              0.00000    0.0    0.0                      0.0   \n",
      "1   0.0     0.0              0.08765    0.0    0.0                      0.0   \n",
      "2   0.0     0.0              0.00000    0.0    0.0                      0.0   \n",
      "\n",
      "   aassists  aatchoo  ...  zombo  zone  zoo  zoomed  zorasterism  zubov  \\\n",
      "0       0.0      0.0  ...    0.0   0.0  0.0     0.0          0.0    0.0   \n",
      "1       0.0      0.0  ...    0.0   0.0  0.0     0.0          0.0    0.0   \n",
      "2       0.0      0.0  ...    0.0   0.0  0.0     0.0          0.0    0.0   \n",
      "\n",
      "   zupancic  zurich  zwart  zzzzzz  \n",
      "0       0.0     0.0    0.0     0.0  \n",
      "1       0.0     0.0    0.0     0.0  \n",
      "2       0.0     0.0    0.0     0.0  \n",
      "\n",
      "[3 rows x 19206 columns]\n",
      "* * * * * * * * * * * * * * * * * * * * \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LatentDirichletAllocation(max_iter=100, n_components=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LatentDirichletAllocation</label><div class=\"sk-toggleable__content\"><pre>LatentDirichletAllocation(max_iter=100, n_components=2)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LatentDirichletAllocation(max_iter=100, n_components=2)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Vectorize the text\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(data['clean_text'])\n",
    "X = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "print(X.head(3))\n",
    "print(\"* \"*20)\n",
    "\n",
    "# Train the LDA model\n",
    "n_components = 2\n",
    "lda = LatentDirichletAllocation(n_components=n_components, max_iter=100)\n",
    "lda.fit(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  (3) Visualize potential topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéÅ We coded for you a  function that prints the words associated with the potential topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_topics(model, vectorizer):\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (idx))\n",
    "        print([(vectorizer.get_feature_names_out()[i], topic[i])\n",
    "                        for i in topic.argsort()[:-10 - 1:-1]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question** ‚ùì Print the topics extracted by your LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "[('god', 35.83244031444331), ('christian', 22.515181868001036), ('jesus', 19.132054714187067), ('people', 17.596444414773664), ('would', 16.762166976788347), ('church', 16.574066443433946), ('one', 16.47974288345757), ('bible', 13.827861695007067), ('believe', 13.703478312342906), ('say', 13.139484110133772)]\n",
      "Topic 1:\n",
      "[('game', 26.940861494896726), ('team', 25.649498410089638), ('hockey', 18.67018280111222), ('player', 18.319798251840233), ('go', 15.522639576074832), ('play', 14.593812262122475), ('nhl', 13.573322092287574), ('year', 13.39512325067377), ('playoff', 13.255668125765654), ('university', 12.956343105525674)]\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "print_topics(lda, vectorizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Predict the document-topic mixture of a new text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (Prediction)** ‚ùì\n",
    "\n",
    "Now that your LDA model is fitted, you can use it to predict the topics of a new text.\n",
    "\n",
    "1. Vectorize the example\n",
    "2. Use the LDA on the vectorized example to predict the topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = [\"My team performed poorly last season. Their best player was out injured and only played one game\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.14782687 0.85217313]]\n",
      "[1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tanushrinayak/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but LatentDirichletAllocation was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# Vecrorize the 'example'\n",
    "example = vectorizer.transform(example)\n",
    "\n",
    "# Use the LDA model to predict the topics of the 'example' text and print the  topic names\n",
    "print(lda.transform(example))\n",
    "print(lda.transform(example).argmax(axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaauuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuugggggggggggggggg</th>\n",
       "      <th>aacc</th>\n",
       "      <th>aadams</th>\n",
       "      <th>aafreenetcarletonca</th>\n",
       "      <th>aargh</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aaronbinahccbrandeisedu</th>\n",
       "      <th>aassists</th>\n",
       "      <th>aatchoo</th>\n",
       "      <th>...</th>\n",
       "      <th>zombo</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoomed</th>\n",
       "      <th>zorasterism</th>\n",
       "      <th>zubov</th>\n",
       "      <th>zupancic</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zwart</th>\n",
       "      <th>zzzzzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.878691</td>\n",
       "      <td>0.505132</td>\n",
       "      <td>0.533998</td>\n",
       "      <td>0.500094</td>\n",
       "      <td>1.733956</td>\n",
       "      <td>0.504016</td>\n",
       "      <td>1.795785</td>\n",
       "      <td>0.774057</td>\n",
       "      <td>0.501148</td>\n",
       "      <td>0.640062</td>\n",
       "      <td>...</td>\n",
       "      <td>0.502259</td>\n",
       "      <td>0.504272</td>\n",
       "      <td>0.504058</td>\n",
       "      <td>0.503915</td>\n",
       "      <td>0.580897</td>\n",
       "      <td>0.504485</td>\n",
       "      <td>0.501248</td>\n",
       "      <td>0.503013</td>\n",
       "      <td>0.838437</td>\n",
       "      <td>0.503404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.525538</td>\n",
       "      <td>0.596298</td>\n",
       "      <td>0.500611</td>\n",
       "      <td>0.506393</td>\n",
       "      <td>0.577039</td>\n",
       "      <td>1.276513</td>\n",
       "      <td>0.504583</td>\n",
       "      <td>0.502906</td>\n",
       "      <td>0.576773</td>\n",
       "      <td>0.508866</td>\n",
       "      <td>...</td>\n",
       "      <td>0.764234</td>\n",
       "      <td>2.587097</td>\n",
       "      <td>0.660956</td>\n",
       "      <td>0.761463</td>\n",
       "      <td>0.502202</td>\n",
       "      <td>1.768031</td>\n",
       "      <td>0.586746</td>\n",
       "      <td>0.656323</td>\n",
       "      <td>0.504918</td>\n",
       "      <td>0.680752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows √ó 19206 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         aa  \\\n",
       "0  0.878691   \n",
       "1  0.525538   \n",
       "\n",
       "   aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaauuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuugggggggggggggggg  \\\n",
       "0                                           0.505132                                 \n",
       "1                                           0.596298                                 \n",
       "\n",
       "       aacc    aadams  aafreenetcarletonca     aargh     aaron  \\\n",
       "0  0.533998  0.500094             1.733956  0.504016  1.795785   \n",
       "1  0.500611  0.506393             0.577039  1.276513  0.504583   \n",
       "\n",
       "   aaronbinahccbrandeisedu  aassists   aatchoo  ...     zombo      zone  \\\n",
       "0                 0.774057  0.501148  0.640062  ...  0.502259  0.504272   \n",
       "1                 0.502906  0.576773  0.508866  ...  0.764234  2.587097   \n",
       "\n",
       "        zoo    zoomed  zorasterism     zubov  zupancic    zurich     zwart  \\\n",
       "0  0.504058  0.503915     0.580897  0.504485  0.501248  0.503013  0.838437   \n",
       "1  0.660956  0.761463     0.502202  1.768031  0.586746  0.656323  0.504918   \n",
       "\n",
       "     zzzzzz  \n",
       "0  0.503404  \n",
       "1  0.680752  \n",
       "\n",
       "[2 rows x 19206 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the topics of the 'example'\n",
    "topic_words = pd.DataFrame(\n",
    "    lda.components_,\n",
    "    columns=vectorizer.get_feature_names_out()\n",
    ")\n",
    "topic_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.83244031444331\n",
      "god\n",
      "26.940861494896726\n",
      "game\n"
     ]
    }
   ],
   "source": [
    "# Print the max value od row 0 and its corresponding column name\n",
    "print(topic_words.iloc[0].max())\n",
    "print(topic_words.iloc[0].idxmax())\n",
    "\n",
    "# Print the max value od row 1 and its corresponding column name\n",
    "print(topic_words.iloc[1].max())\n",
    "print(topic_words.iloc[1].idxmax())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üèÅ Congratulations! You know how to implement an LDA quickly.\n",
    "\n",
    "üíæ Don't forget to¬†`git add/commit/push`¬†your notebook...\n",
    "\n",
    "üöÄ ... and move on to the next challenge!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
